# Vis resultatet
data
# Generer en liste med 100 tilfældige kreditposter mellem 100 og 1000
kredit <- sample(100:1000, 100, replace = TRUE)
# Beregn den samlede kredit for at finde en passende grænseværdi for debitposterne
total_kredit <- sum(kredit)
# Generer en liste med 100 tilfældige debitposter mellem 1 og den samlede kredit
debit <- sample(1:total_kredit/100, 100, replace = TRUE)
# Opret en tabel med kredit- og debitposterne
data <- data.frame(Kredit = kredit, Debit = debit)
# Vis resultatet
data
# Generer en liste med 100 tilfældige debitposter mellem 1 og den samlede kredit
debit <- sample(100:total_kredit/100, 100, replace = TRUE)
# Generer en liste med 100 tilfældige kreditposter mellem 100 og 1000
kredit <- sample(100:1000, 100, replace = TRUE)
# Beregn den samlede kredit for at finde en passende grænseværdi for debitposterne
total_kredit <- sum(kredit)
# Generer en liste med 100 tilfældige debitposter mellem 1 og den samlede kredit
debit <- sample(100:total_kredit/100, 100, replace = TRUE)
# Opret en tabel med kredit- og debitposterne
data <- data.frame(Kredit = kredit, Debit = debit)
# Vis resultatet
data
# Gennemgå hver delmængde af debitposter og find matchende kombinationer af kreditposter
for (chunk_start in seq(1, nrow(data), by = chunk_size)) {
chunk_end <- min(chunk_start + chunk_size - 1, nrow(data))
chunk <- data[chunk_start:chunk_end, ]
# Gennemgå hver debitpost i delmængden og find matchende kombinationer af kreditposter
for (i in seq_along(chunk$Debit)) {
# Find alle kombinationer af kreditposter, der svarer til debitposten
partitions <- compositions(chunk$Debit[i], length(chunk$Kredit))
combinations <- t(sapply(partitions, function(p) {
kredit <- sum(chunk$Kredit[!is.na(chunk$Kredit)][p])
if (!is.na(kredit) && kredit == chunk$Debit[i]) {
p
} else {
rep(NA, length(p))
}
}))
combinations <- na.omit(combinations)
# Hvis der er matchende kombinationer, gem dem i Kredit1- og Kredit2-kolonnerne
n_combinations <- nrow(combinations)
if (n_combinations > 0) {
data$Kredit1[chunk_start + i - 1] <- paste(combinations[1, ], collapse = ", ")
if (n_combinations > 1) {
data$Kredit2[chunk_start + i - 1] <- paste(combinations[2, ], collapse = ", ")
}
}
print(paste("Debit:", chunk$Debit[i], "Kreditkombinationer:", combinations))
}
}
# Vis resultatet
data
# Opret to nye kolonner
data$Kredit1 <- NA
data$Kredit2 <- NA
# Angiv antallet af debitposter, der skal behandles i hver iteration
chunk_size <- 2
# Gennemgå hver delmængde af debitposter og find matchende kombinationer af kreditposter
for (chunk_start in seq(1, nrow(data), by = chunk_size)) {
chunk_end <- min(chunk_start + chunk_size - 1, nrow(data))
chunk <- data[chunk_start:chunk_end, ]
# Gennemgå hver debitpost i delmængden og find matchende kombinationer af kreditposter
for (i in seq_along(chunk$Debit)) {
# Find alle kombinationer af kreditposter, der svarer til debitposten
partitions <- compositions(chunk$Debit[i], length(chunk$Kredit))
combinations <- t(sapply(partitions, function(p) {
kredit <- sum(chunk$Kredit[!is.na(chunk$Kredit)][p])
if (!is.na(kredit) && kredit == chunk$Debit[i]) {
p
} else {
rep(NA, length(p))
}
}))
combinations <- na.omit(combinations)
# Hvis der er matchende kombinationer, gem dem i Kredit1- og Kredit2-kolonnerne
n_combinations <- nrow(combinations)
if (n_combinations > 0) {
data$Kredit1[chunk_start + i - 1] <- paste(combinations[1, ], collapse = ", ")
if (n_combinations > 1) {
data$Kredit2[chunk_start + i - 1] <- paste(combinations[2, ], collapse = ", ")
}
}
print(paste("Debit:", chunk$Debit[i], "Kreditkombinationer:", combinations))
}
}
# Vis resultatet
data
View(chunk)
View(combinations)
# Opret en tabel med dine data
data <- data.frame(
Kredit = c(100, 200, 300, 400, 0),
Debit = c(550, 250, 750, 650, 350)
)
# Opret en tabel med dine data
data <- data.frame(
Kredit = c(100, 200, 300, 400, 500,1000,0),
Debit = c(550, 250, 750, 650, 350,500,500)
)
# Opret to nye kolonner
data$Kredit1 <- NA
data$Kredit2 <- NA
# Angiv antallet af debitposter, der skal behandles i hver iteration
chunk_size <- 2
# Gennemgå hver delmængde af debitposter og find matchende kombinationer af kreditposter
for (chunk_start in seq(1, nrow(data), by = chunk_size)) {
chunk_end <- min(chunk_start + chunk_size - 1, nrow(data))
chunk <- data[chunk_start:chunk_end, ]
# Gennemgå hver debitpost i delmængden og find matchende kombinationer af kreditposter
for (i in seq_along(chunk$Debit)) {
# Find alle kombinationer af kreditposter, der svarer til debitposten
partitions <- compositions(chunk$Debit[i], length(chunk$Kredit))
combinations <- t(sapply(partitions, function(p) {
kredit <- sum(chunk$Kredit[!is.na(chunk$Kredit)][p])
if (!is.na(kredit) && kredit == chunk$Debit[i]) {
p
} else {
rep(NA, length(p))
}
}))
combinations <- na.omit(combinations)
# Hvis der er matchende kombinationer, gem dem i Kredit1- og Kredit2-kolonnerne
n_combinations <- nrow(combinations)
if (n_combinations > 0) {
data$Kredit1[chunk_start + i - 1] <- paste(combinations[1, ], collapse = ", ")
if (n_combinations > 1) {
data$Kredit2[chunk_start + i - 1] <- paste(combinations[2, ], collapse = ", ")
}
}
print(paste("Debit:", chunk$Debit[i], "Kreditkombinationer:", combinations))
}
}
# Opret en tabel med dine data
data <- data.frame(
Kredit = c(100, 200, 300, 400, 500,500, 500),
Debit = c(550, 250, 750, 650, 350,1000,0)
)
# Opret to nye kolonner
data$Kredit1 <- NA
data$Kredit2 <- NA
# Angiv antallet af debitposter, der skal behandles i hver iteration
chunk_size <- 2
# Gennemgå hver delmængde af debitposter og find matchende kombinationer af kreditposter
for (chunk_start in seq(1, nrow(data), by = chunk_size)) {
chunk_end <- min(chunk_start + chunk_size - 1, nrow(data))
chunk <- data[chunk_start:chunk_end, ]
# Gennemgå hver debitpost i delmængden og find matchende kombinationer af kreditposter
for (i in seq_along(chunk$Debit)) {
# Find alle kombinationer af kreditposter, der svarer til debitposten
partitions <- compositions(chunk$Debit[i], length(chunk$Kredit))
combinations <- t(sapply(partitions, function(p) {
kredit <- sum(chunk$Kredit[!is.na(chunk$Kredit)][p])
if (!is.na(kredit) && kredit == chunk$Debit[i]) {
p
} else {
rep(NA, length(p))
}
}))
combinations <- na.omit(combinations)
# Hvis der er matchende kombinationer, gem dem i Kredit1- og Kredit2-kolonnerne
n_combinations <- nrow(combinations)
if (n_combinations > 0) {
data$Kredit1[chunk_start + i - 1] <- paste(combinations[1, ], collapse = ", ")
if (n_combinations > 1) {
data$Kredit2[chunk_start + i - 1] <- paste(combinations[2, ], collapse = ", ")
}
}
print(paste("Debit:", chunk$Debit[i], "Kreditkombinationer:", combinations))
}
}
# Opret en tabel med dine data
data <- data.frame(
Kredit = c(100, 200, 300, 400, 500,500),
Debit = c(550, 250, 750, 650, 350,1000)
)
# Opret to nye kolonner
data$Kredit1 <- NA
data$Kredit2 <- NA
# Angiv antallet af debitposter, der skal behandles i hver iteration
chunk_size <- 2
# Gennemgå hver delmængde af debitposter og find matchende kombinationer af kreditposter
for (chunk_start in seq(1, nrow(data), by = chunk_size)) {
chunk_end <- min(chunk_start + chunk_size - 1, nrow(data))
chunk <- data[chunk_start:chunk_end, ]
# Gennemgå hver debitpost i delmængden og find matchende kombinationer af kreditposter
for (i in seq_along(chunk$Debit)) {
# Find alle kombinationer af kreditposter, der svarer til debitposten
partitions <- compositions(chunk$Debit[i], length(chunk$Kredit))
combinations <- t(sapply(partitions, function(p) {
kredit <- sum(chunk$Kredit[!is.na(chunk$Kredit)][p])
if (!is.na(kredit) && kredit == chunk$Debit[i]) {
p
} else {
rep(NA, length(p))
}
}))
combinations <- na.omit(combinations)
# Hvis der er matchende kombinationer, gem dem i Kredit1- og Kredit2-kolonnerne
n_combinations <- nrow(combinations)
if (n_combinations > 0) {
data$Kredit1[chunk_start + i - 1] <- paste(combinations[1, ], collapse = ", ")
if (n_combinations > 1) {
data$Kredit2[chunk_start + i - 1] <- paste(combinations[2, ], collapse = ", ")
}
}
print(paste("Debit:", chunk$Debit[i], "Kreditkombinationer:", combinations))
}
}
# Vis resultatet
data
victorspref=='at være til mænd'
victorspref<- "hej"
victorspref=='at være til mænd'
victorspref<- 'at være til mænd'
victorspref=='at være til mænd'
### ARIMA Proff of Concept
setwd("C:/Users/madsh/OneDrive/Dokumenter/kandidat/Fællesmappe/Speciale/Data/Data fra energidataservice.dk"
df <- read.csv("Production and Consumption - Settlement.csv")
df <- read.csv2("Production and Consumption - Settlement.csv")
df <- read.csv("Production and Consumption - Settlement.csv")
df <- read.csv("Production and Consumption - Settlement.csv")
# Angiv stien til mappen, hvor CSV-filerne er placeret
mappe <- "C:/Users/madsh/OneDrive/Dokumenter/kandidat/Fællesmappe/Speciale/Data/Vejr data"
# Få en liste over CSV-filerne i mappen
filer <- list.files(path = mappe, pattern = "*.csv", full.names = TRUE)
df2 <- read.csv2(filer[2],sep=",",header = T)
df1 <- read.csv2(filer[1],sep = ",",header = F)
df1 <- df1[-1,]
colnames(df1)<- colnames(df2)
df3 <- read.csv2(filer[3],sep=",",header = T)
df4 <- read.csv2(filer[4],sep=",",header = T)
df5 <- read.csv2(filer[5],sep=",",header = T)
samlet_data <- rbind(df1,df2,df3,df4,df5)
head(samlet_data[1])
tail(samlet_data[1])
write.csv(samlet_data,"vejr data.csv")
write.csv(samlet_data,"vejr data.csv")
write.csv(samlet_data,"C:/Users/madsh/OneDrive/Dokumenter/kandidat/Fællesmappe/Speciale/Data/Vejr data/vejr data.csv")
# Load required libraries
library(caret)
library(Metrics)
# Load required libraries
library(caret)
# Load required libraries
library(caret)
# Load the dataset
filepath <- 'C:/Users/madsh/OneDrive/Dokumenter/kandidat/Fællesmappe/Semester 3/Applied Machine learning and Data Engerneering in a busineess context/Afleveringsopgave 1/combined_daily_flagged.csv'
data_flagged <- read.csv(filepath)
# Set HourDK as DataFrame index (in R, row names)
rownames(data_flagged) <- data_flagged$HourDK
data_flagged$HourDK <- NULL
# Split the data into training and test sets
training_set <- subset(data_flagged, as.Date(rownames(data_flagged)) <= '2022-06-30')
test_set <- subset(data_flagged, as.Date(rownames(data_flagged)) > '2022-06-30')
# Define features and target variable for training set
X_train <- training_set
y_train <- X_train$GrossConsumptionMWh
X_train$GrossConsumptionMWh <- NULL
# Define features for test set
X_test <- test_set
y_test <- X_test$GrossConsumptionMWh
X_test$GrossConsumptionMWh <- NULL
# Create a model
model <- lm(GrossConsumptionMWh ~ ., data = cbind(GrossConsumptionMWh = y_train, X_train))
# Custom predict function
custom_predict <- function(X, model) {
y_pred <- predict(model, X)
y_custom_pred <- ifelse(X$flagged == 1, 0, y_pred)
return(y_custom_pred)
}
# Predict the target for the test set
y_pred <- custom_predict(X_test, model)
# Metrics function
metrics <- function(y_test, y_pred) {
mse <- mean((y_test - y_pred)^2)
rmse <- sqrt(mse)
mae <- mean(abs(y_test - y_pred))
r2 <- 1 - (sum((y_test - y_pred)^2) / sum((y_test - mean(y_test))^2))
cat("MSE =", mse, "/nRMSE =", rmse, "/nMAE =", mae, "/nR2 =", r2, "/n")
}
# Calculate metrics
metrics(y_test, y_pred)
summary(model)
View(data_flagged)
data_flagged <- read.csv(filepath)
View(data_flagged)
################################################################################
# Load the dataset
filepath <- 'C:/Users/madsh/OneDrive/Dokumenter/kandidat/Fællesmappe/Speciale/Forecasting-energy-consumption-in-Denmark/Data/Combined data/combined_daily_flagged.csv'
data_flagged <- read.csv(filepath)
# Set HourDK as DataFrame index (in R, row names)
rownames(data_flagged) <- data_flagged$HourDK
data_flagged$HourDK <- NULL
# Split the data into training and test sets
training_set <- subset(data_flagged, as.Date(rownames(data_flagged)) <= '2022-06-30')
test_set <- subset(data_flagged, as.Date(rownames(data_flagged)) > '2022-06-30')
# Define features and target variable for training set
X_train <- training_set
y_train <- X_train$GrossConsumptionMWh
X_train$GrossConsumptionMWh <- NULL
# Define features for test set
X_test <- test_set
y_test <- X_test$GrossConsumptionMWh
X_test$GrossConsumptionMWh <- NULL
# Create a model
model <- lm(GrossConsumptionMWh ~ ., data = cbind(GrossConsumptionMWh = y_train, X_train))
summary(model)
View(data_flagged)
summary(data_flagged$Month_December)
is.na(data_flagged$Month_December)
y_pred <- custom_predict(X_test, model)
# Calculate metrics
metrics(y_test, y_pred)
# Calculate metrics
metrics(y_test, y_pred)
summary(model)
metrics(y_test, y_pred)
# Liste med navne
navne <- c("Navn1", "Navn2", "Navn3", "Navn4", "Navn5")
# Angiv stien til mappen, hvor filerne skal gemmes
gem_mappe <- "C:/Users/madsh/OneDrive/Dokumenter/kandidat/Nissevenenr Danyi"
# Tjekker om der er nok navne til at oprette nissevenner
if (length(navne) < 2) {
stop("Der skal være mindst to navne for at kunne oprette nissevenner.")
}
# Funktion til at lave nissevenner
lavNisseVenner <- function(navne) {
# Tilfældig rækkefølge af navnene
shuffled_navne <- sample(navne)
# Opretter en tom liste til at gemme par af nissevenner
nissevenner_par <- list()
# Loop igennem navnene og opretter par
for (i in 1:length(navne)) {
giver <- navne[i]
modtager <- shuffled_navne[i %% length(navne) + 1]
# Tjekker om modtageren allerede er blevet tildelt som nisseven
while (modtager %in% unlist(nissevenner_par) || giver == modtager) {
shuffled_navne <- sample(shuffled_navne)
modtager <- shuffled_navne[i %% length(navne) + 1]
}
# Gemmer parret i listen
nissevenner_par[[i]] <- list(giver = giver, modtager = modtager)
}
return(nissevenner_par)
}
# Lav nissevenner
nissevenner <- lavNisseVenner(navne)
# Indtast navne listen her
navne <- c("Alice", "Bob", "Charlie", "David", "Eva")
# Funktion til at generere unikke par uden at parre nogen med sig selv
generate_pairs <- function(names) {
repeat {
shuffled_names <- sample(names)
if (!any(names == shuffled_names)) {
return(shuffled_names)
}
}
}
# Generer de unikke par
pairs <- generate_pairs(navne)
# Mappe hvor txt filer skal gemmes
file_path <- "C:/Users/madsh/OneDrive/Dokumenter/kandidat/Nissevenner Danyi"
# Tjek om mappen findes, hvis ikke, så opret den
if (!dir.exists(file_path)) {
dir.create(file_path, recursive = TRUE)
}
# Opret en txt-fil for hvert navn med et andet navn fra listen
for (i in seq_along(navne)) {
file_name <- file.path(file_path, paste0(navne[i], ".txt"))
writeLines(pairs[i], file_name)
}
# Udskriv besked om at filerne er oprettet
cat("Nissevenner filer er blevet oprettet i mappen:", file_path)
install.packages('forecast')
library(tidyverse)
library(forecast)
install.packages('forecast')
library(forecast)
install.packages('forecast')
library(tidyverse)
library(forecast)
# Forecsting remainders with OLS
## Libraries
library(tidyverse)
library(forecast)
library(ggplot2)
library(dplyr)
library(data.table)
library(IRdisplay)
library(progress)
library(foreach)
library(doParallel)
library(caret)
library(randomForest)
## Custom functions
display_limited <- function(dt) {
n <- nrow(dt)
# If there are 20 or fewer rows, display the full table
if (n <= 20) {
limited_dt <- dt
} else {
# Otherwise, concatenate the first 5 rows, '...' and the last 5 rows
limited_dt <- rbind(head(dt, 5), as.list(rep("...", ncol(dt))), tail(dt, 5))
}
# Generate raw HTML manually
html_output <- paste0(
"<table border='1' style='border-collapse:collapse;'>",
"<thead><tr>",
paste0("<th>", colnames(limited_dt), "</th>", collapse = ""),
"</tr></thead>",
"<tbody>",
paste0(
apply(limited_dt, 1, function(row) {
paste0("<tr>", paste0("<td>", row, "</td>", collapse = ""), "</tr>")
}),
collapse = ""
),
"</tbody></table>"
)
# Display the HTML in the Jupyter notebook
display_html(html_output)
}                                # Display tables
calculate_metrics <- function(R_t, R_hat_t, individual) {
# Ensure the inputs are numeric vectors and individual is a dataframe
if (!is.numeric(R_t) || !is.numeric(R_hat_t)) {
stop("Both R_t and R_hat_t need to be numeric vectors.")
}
# Calculate metrics
mae <- mean(abs(R_t - R_hat_t), na.rm = TRUE)
rmse <- sqrt(mean((R_t - R_hat_t)^2, na.rm = TRUE))
mape <- mean(abs((R_t - R_hat_t) / R_t), na.rm = TRUE) * 100
r_squared <- ifelse(all(R_t == R_hat_t), 1, summary(lm(R_t ~ R_hat_t))$r.squared)
# Create a data frame to hold the metrics and values
metrics_table <- data.frame(
MAE = mae,
RMSE = rmse,
MAPE = mape,
R_squared = r_squared
)
# Return the metrics table
return(metrics_table)
}        # Calculate metrics
prepare_X_t <- function(individual) {
# Ensure the input is a dataframe
if (!is.data.frame(individual)) {
stop("The input must be a dataframe.")
}
# Extract hour from start_time and create a 'time_of_day' column
individual$time_of_day <- format(as.POSIXct(individual$HourDK), "%H:%M:%S")
# Exclude specified columns but keep 'time_of_day'
X_t <- subset(individual, select = -c(HourDK, GrossConsumptionMWh))
# Convert month, weekday, and time_of_day to factors with a reference category
X_t$month <- relevel(as.factor(X_t$MonthOfYear), ref = "December")  # Set December as reference
X_t$weekday <- relevel(as.factor(X_t$DayOfWeek), ref = "Sunday")   # Set Sunday as reference
X_t$time_of_day <- relevel(as.factor(X_t$Hour), ref = "0")         # Set 23 (11 PM) as reference
# Remove original 'MonthOfYear', 'DayOfWeek', and 'Hour' columns to avoid duplication
X_t <- subset(X_t, select = -c(MonthOfYear, DayOfWeek, Hour))
# Create dummy variables for all factor columns (excluding reference levels)
X_t <- model.matrix(~ . - 1, data = X_t)
# Find the column indices for numerical columns AFTER creating dummy variables
num_cols <- grep("^(Electric cars|Plug-in hybrid cars|humidity_past1h|temp_mean_past1h|wind_speed_past1h|EL_price)", colnames(X_t))
# Standardize selected numerical columns
X_t[, num_cols] <- apply(X_t[, num_cols], 2,
function(x) (x - min(x)) / (max(x) - min(x)))
# Return the processed dataframe
return(as.data.frame(X_t))
}                            # Data Preparation
lag_and_align_data <- function(X_t, R_t, h = 1) {
# Validate inputs
if (!is.numeric(R_t)) {
stop("R_t should be a numeric vector.")
}
if (!is.data.frame(X_t) && !is.matrix(X_t)) {
stop("X_t should be a dataframe or a matrix.")
}
if (!is.numeric(h) || h < 1) {
stop("h should be a positive integer.")
}
# Convert X_t to a dataframe if it's a matrix
if (is.matrix(X_t)) {
X_t <- as.data.frame(X_t)
}
# Align R_t with the lagged X_t
# Shift R_t by h positions to align with X_t from the previous timestep
R_t_aligned <- R_t[(h + 1):length(R_t)]
# Keep X_t up to the second to last row, so it aligns with the shifted R_t
X_t_aligned <- X_t[1:(nrow(X_t) - h), ]
# Return the aligned datasets
list(X_t = X_t_aligned, R_t = R_t_aligned)
}                # Lag and Align data by \\(h\\) (horizon)
plot_actual_vs_estimated <- function(R_t, R_hat_t, individual) {
# Validate input
if (!is.numeric(R_t) || !is.numeric(R_hat_t)) {
stop("R_t and R_hat_t should be numeric vectors.")
}
if (!is.data.frame(individual)) {
stop("individual should be a dataframe.")
}
# Create the plot
plot(R_t, type = 'l', col = 'blue', xlab = "Time", ylab = "Value",
main = "Actual vs. Estimated Time Series\nelvarme: %s, zip_code: %s")
lines(R_hat_t, type = 'l', col = 'red')
legend("topleft", legend = c("Actual", "Estimated"), col = c("blue", "red"), lty = 1)
} # Plot actual vs estimated
## Loading data
##### Setting workign directory and loadign data #####
base_path <- "C:/Users/madsh/OneDrive/Dokumenter/kandidat/Fællesmappe/Forecasting-energy-consumption/Data Cleaning"
setwd(base_path)
data <- fread(paste0(base_path,"/Output_file.csv"))
MSTL <- fread(paste0(base_path,"/MSTL_decomp_results.csv"))
